# -*- coding: utf-8 -*-
"""diet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1otycN8dgDw8KAImpF5D6k9NKLPFZpauP
"""

from google.colab import drive
drive.mount('/content/drive',force_remount = True)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras import optimizers
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from keras import regularizers

import csv
import pandas as pd
pd.set_option('display.max_colwidth', -1)

df = pd.read_csv('/content/drive/My Drive/HackZurich/diet_train.csv', encoding = 'utf-8')
test = pd.read_csv('/content/drive/My Drive/HackZurich/diet_test.csv', encoding = 'utf-8')
#sample = pd.read_csv('/content/drive/My Drive/HackZurich/sample.csv')
#df.head(10)
df.head(10)

df.Glucose.hist()
plt.show()

df.LDL.hist()
plt.show()

min_max_scaler = preprocessing.MinMaxScaler()
#Scaling The Training Data
x = df.values
x_scaled = min_max_scaler.fit_transform(x)
df = pd.DataFrame(x_scaled)
#Scaling The Testing Data
y = test.values
y_scaled = min_max_scaler.fit_transform(y)
test = pd.DataFrame(y_scaled)
df.head(10)

df[0].hist() #Glucose Concentration
plt.show()

df[2].hist() #LDL
plt.show()

train, dev = train_test_split(df, test_size = 0.3)

hidden_units = 300
learning_rate = 0.005 #Learning rate was quite optimal
hidden_layer_act = 'tanh'
output_layer_act = 'sigmoid'
no_epochs = 500 
bsize = 64 #Batch Size Of 128

model = Sequential()
model.add(Dense(hidden_units, input_dim = 5, activation = hidden_layer_act))
model.add(Dense(hidden_units, activation = hidden_layer_act))
model.add(Dense(1, activation = output_layer_act))
print (model.summary())

adam = optimizers.Adam(lr = learning_rate, beta_1 = 0.9, beta_2 = 0.999, epsilon = None, decay = 0.0, amsgrad = False)
model.compile(loss ='binary_crossentropy',optimizer = adam, metrics = ['acc'])

train_x = train.iloc[:,1:6]
train_y = train.iloc[:,6]

model.fit(train_x, train_y, epochs = no_epochs, batch_size = bsize,  verbose = 2)

val_loss, val_acc = model.evaluate(dev.iloc[:,1:6], dev.iloc[:,6])
print("Validation Loss : ", val_loss)
print("Validation Acc : ",val_acc)

test_x = test.iloc[:,1:6]
predictions = model.predict(test_x)
print(predictions)

rounded = [int(round(x[0])) for x in predictions]
print(rounded)

def countX(rounded, x): 
    return rounded.count(x)

x = 0
y = 1
print('{} has occurred {} times'.format(x, countX(rounded, x))) 
print('{} has occurred {} times'.format(y, countX(rounded, y)))

"""Confusion Matrix for the same

60 22

27 169
"""